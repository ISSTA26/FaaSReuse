# FaaSReuse: LLM-Enhanced Function Reuse for Serverless Computing

This repository provides the implementation of **FaaSReuse**, along with the evaluation dataset, baseline methods, and experimental results used in our study.

---

## Framework Implementation

The FaaSReuse framework consists of the following core scripts, supporting multiple large language models (LLMs):

- **`faasReuse_representation.py`**  
  Encodes serverless functions into structured representations and stores them in JSON format for subsequent retrieval.

- **`faasReuse_recommend.py`**  
  Retrieves and ranks highly relevant functions in response to user task requests.

Additionally, the following utility scripts are provided:

- **`mapping.py`**  
  Constructs a terminology mapping table to normalize heterogeneous function descriptions.

- **`pareto.py`**  
  Filters out irrelevant functions based on task requirements and produces a refined candidate set for recommendation.

---

## Evaluation Dataset

- **`Serverless Function Reuse.xlsx`**  
  Contains 500 serverless functions, including function IDs, original names, and source links.

- **`Task queries.xlsx`**  
  Includes 150 task queries extracted from GitHub README files, along with their corresponding source links.

---

## Evaluation Baselines

### Baseline 1: Keyword-Based Method (`Baselines/`)
- **`keywords_dataset.py`**  
  Extracts keywords from function code using stop-word removal and stemming, and stores them in JSON format.

- **`keywords_retrive.py`**  
  Extracts keywords from user requests and matches them against the function keyword dataset.

---

### Baseline 2: Embedding-Based Method (`Baselines/`)
- **`embedding_dataset.py`**  
  Encodes function code into dense embedding vectors using a pre-trained sentence encoder and stores them in JSON format.

- **`embedding_retrive.py`**  
  Encodes user requests into embedding vectors and ranks candidate functions based on cosine similarity.

---

### Baseline 3: Customized LLM-Based Method (`Baselines/`)
- **`customized_retrive.py`**  
  Uses LLMs to generate intent summaries from user requests, encodes them into semantic embeddings via a pre-trained sentence encoder, and retrieves functions using cosine similarity. Unlike FaaSReuse, this baseline does not exploit multi-dimensional structural information.

---

## Evaluation Results

Experimental results corresponding to **RQ1â€“RQ5** are provided in the directory **`EvaluationResults/`**:

- **`RQ1/`**  
  Metric results and JSON outputs for the keyword-based (Baseline 1) and embedding-based (Baseline 2) methods.

- **`RQ2/`**  
  Metric results and JSON outputs for the customized LLM-based method (Baseline 3), repeated five times.

- **`RQ3/`**  
  Metric results and JSON outputs for FaaSReuse under different temperature settings (0, 0.2, 0.5), repeated five times.

- **`RQ4/`**  
  Metric results and JSON outputs for FaaSReuse evaluated with different LLMs (Llama 3.1 (405B) Instruct Turbo, Gemini 2.0 Flash, and DeepSeek V3), repeated five times.

- **`RQ5/`**  
  Sampled task queries and the corresponding code generated by LLMs.
